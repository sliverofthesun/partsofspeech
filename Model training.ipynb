{"cells":[{"cell_type":"markdown","source":["# Model training"],"metadata":{"id":"QDH_qzgder11"}},{"cell_type":"code","source":["from google.colab import drive\n","import numpy as np\n","import os\n","import pickle\n","from sklearn.metrics import f1_score\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n","from tensorflow.keras.layers import Bidirectional, Dense, LSTM, TimeDistributed\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical"],"metadata":{"id":"YAzzUtEneum_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20869,"status":"ok","timestamp":1708436371216,"user":{"displayName":"r4wtgrh","userId":"14922680703818809666"},"user_tz":-60},"id":"t-9VMslABgaj","outputId":"983a7267-fefd-4609-f116-87466fcc073a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLQ9KEE1B75s"},"outputs":[],"source":["def data_generator(data_path, batch_size, n_tags):\n","    # List all .pkl files in the data_path directory, sorted alphabetically\n","    files = [os.path.join(data_path, f) for f in sorted(os.listdir(data_path)) if f.endswith('.pkl')]\n","    # Infinite loop to allow the generator to yield data indefinitely\n","    while True:\n","        # Iterate through each file in the sorted list of .pkl files\n","        for filepath in files:\n","            # Open the .pkl file in read-binary mode\n","            with open(filepath, 'rb') as file:\n","                # Load the data (features and labels) from the .pkl file\n","                X, y = pickle.load(file)\n","                # Convert the labels to one-hot encoding format based on the number of tags\n","                y = to_categorical(y, num_classes=n_tags)\n","                # Yield batches of the data and labels\n","                for i in range(0, len(X), batch_size):\n","                    yield X[i:i+batch_size], y[i:i+batch_size]"]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"H65F_E_bfIqe"}},{"cell_type":"markdown","source":["We create a neural network model for sequence labeling;"],"metadata":{"id":"bICbG9wwpb8O"}},{"cell_type":"code","source":["def create_model(input_shape, n_tags):\n","    # Initialize a Sequential model\n","    model = Sequential([\n","        # Add a Bidirectional LSTM layer\n","        Bidirectional(LSTM(units=64, return_sequences=True, dropout=0.1), input_shape=input_shape),\n","        # Add a TimeDistributed Dense layer for output, with softmax activation\n","        TimeDistributed(Dense(n_tags, activation=\"softmax\"))\n","    ])\n","    # Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric\n","    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model"],"metadata":{"id":"_mVF9uD3fGzS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then we train it our preprocessed data. The model is also saved after each epoch."],"metadata":{"id":"10VZoD38poCf"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nP2LrPQgCsWo","executionInfo":{"status":"ok","timestamp":1708438704669,"user_tz":-60,"elapsed":2327629,"user":{"displayName":"r4wtgrh","userId":"14922680703818809666"}},"outputId":"5f89744b-2faa-4931-ca04-df4a33427acf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional (Bidirection  (None, 30, 128)           186880    \n"," al)                                                             \n","                                                                 \n"," time_distributed (TimeDist  (None, 30, 13)            1677      \n"," ributed)                                                        \n","                                                                 \n","=================================================================\n","Total params: 188557 (736.55 KB)\n","Trainable params: 188557 (736.55 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/10\n","2810/2810 [==============================] - 227s 78ms/step - loss: 0.2736 - accuracy: 0.9204\n","Epoch 2/10\n","   2/2810 [..............................] - ETA: 2:44 - loss: 0.1626 - accuracy: 0.9495"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["2810/2810 [==============================] - 226s 80ms/step - loss: 0.1225 - accuracy: 0.9633\n","Epoch 3/10\n","2810/2810 [==============================] - 229s 81ms/step - loss: 0.1026 - accuracy: 0.9690\n","Epoch 4/10\n","2810/2810 [==============================] - 219s 78ms/step - loss: 0.0902 - accuracy: 0.9725\n","Epoch 5/10\n","2810/2810 [==============================] - 233s 83ms/step - loss: 0.0816 - accuracy: 0.9749\n","Epoch 6/10\n","2810/2810 [==============================] - 219s 78ms/step - loss: 0.0757 - accuracy: 0.9766\n","Epoch 7/10\n","2810/2810 [==============================] - 220s 78ms/step - loss: 0.0710 - accuracy: 0.9779\n","Epoch 8/10\n","2810/2810 [==============================] - 229s 81ms/step - loss: 0.0673 - accuracy: 0.9789\n","Epoch 9/10\n","2810/2810 [==============================] - 221s 78ms/step - loss: 0.0644 - accuracy: 0.9797\n","Epoch 10/10\n","2810/2810 [==============================] - 220s 78ms/step - loss: 0.0619 - accuracy: 0.9804\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78803c307490>"]},"metadata":{},"execution_count":4}],"source":["max_sequence_length = 30\n","embedding_dim = 300\n","n_tags = 13\n","\n","# Create the model with specified input shape and number of tags\n","model = create_model((max_sequence_length, embedding_dim), n_tags)\n","# Print the model summary to show its architecture\n","model.summary()\n","\n","checkpoint_path = \"/content/gdrive/MyDrive/opj/data/checkpoints/model_epoch_{epoch:02d}.hdf5\"\n","\n","# Initialize a ModelCheckpoint callback to save the model at the end of each epoch\n","model_checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    save_weights_only=False,\n","    save_freq='epoch'\n",")\n","\n","train_data_path = '/content/gdrive/MyDrive/opj/data/train'\n","batch_size = 32\n","train_generator = data_generator(train_data_path, batch_size, 13)\n","# Calculate the number of steps per epoch based on the total number of training samples and batch size\n","steps_per_epoch = sum([len(pickle.load(open(os.path.join(train_data_path, f), 'rb'))[0]) for f in os.listdir(train_data_path) if f.endswith('.pkl')]) // batch_size\n","\n","# Training\n","model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=10,\n","    verbose=1,\n","    callbacks=[model_checkpoint_callback]\n",")"]},{"cell_type":"markdown","source":["We see the model took ~37 minutes to train across 10 epochs. If we used the full data, the time taken would be increased by 672 (14 original chunks * 48 later divisions) to 414 hours."],"metadata":{"id":"Q_nIu29bf7pH"}}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPPomwuHgtsg0qepxUMk12/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}